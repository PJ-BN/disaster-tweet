{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a534c1",
   "metadata": {},
   "source": [
    "# Project :Disaster-Tweet\n",
    "\n",
    "    The propose of this notebook is to create a NLP model which classifies the tweet into two part:\n",
    "    * Disaster-tweet :\n",
    "                All the tweet which contains information about the natural disaster happening around the globe will be                         classified as disaster tweet\n",
    "    * Non-disaster tweet :\n",
    "                Except disaster tweet all remaining other tweets is classified as non-disaster tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48613d3e",
   "metadata": {},
   "source": [
    "## Importing all needed module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cfea9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8856799",
   "metadata": {},
   "source": [
    "## Setting up my own helper module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7cb8881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-02-23 16:37:03--  https://raw.githubusercontent.com/PJ-BN/Helper-module/main/helperfunc.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10449 (10K) [text/plain]\n",
      "Saving to: 'helperfunc.py.1'\n",
      "\n",
      "     0K ..........                                            100%  621K=0.02s\n",
      "\n",
      "2023-02-23 16:37:03 (621 KB/s) - 'helperfunc.py.1' saved [10449/10449]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/PJ-BN/Helper-module/main/helperfunc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e7c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helperfunc import calculate_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c40996",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a68ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =\"C:\\\\Users\\\\USER\\\\Documents\\\\ML\\\\NLP\\\\disaster\\\\src\\\\disaster-tweet\\\\\"\n",
    "train_data_dir = data_dir + \"train.csv\"\n",
    "test_data_dir = data_dir + \"test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c7bd08",
   "metadata": {},
   "source": [
    "## Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "115d5621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1    none     none  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4    none     none             Forest fire near La Ronge Sask. Canada   \n",
       "2   5    none     none  All residents asked to 'shelter in place' are ...   \n",
       "3   6    none     none  13,000 people receive #wildfires evacuation or...   \n",
       "4   7    none     none  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_data_dir )\n",
    "test_data = pd.read_csv(test_data_dir)                         \n",
    "\n",
    "train_data = train_data.fillna(\"none\")  \n",
    "test_data = test_data.fillna(\"none\")  \n",
    "\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6989c12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7613 non-null   object\n",
      " 2   location  7613 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9371b98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9a93340",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_data[\"text\"]\n",
    "train_label = train_data[\"target\"]\n",
    "train_location = train_data[\"location\"]\n",
    "train_keyword = train_data[\"keyword\"]\n",
    "\n",
    "test_text = test_data[\"text\"]\n",
    "test_location = test_data[\"location\"]\n",
    "test_keyword = test_data[\"keyword\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "471974e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0    none     none                 Just happened a terrible car crash\n",
       "1   2    none     none  Heard about #earthquake is different cities, s...\n",
       "2   3    none     none  there is a forest fire at spot pond, geese are...\n",
       "3   9    none     none           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11    none     none      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "854dde44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cameroon Repatriated 12000 Nigerian Refugees http://t.co/6nQRU2q5Tz',\n",
       " 'like for the music video I want some real action shit like burning buildings and police chases not some weak ben winston shit',\n",
       " \"I'm on 2 blood pressure meds and it's still probably through the roof! Long before the #PPact story broke I was involved in animal rescue\",\n",
       " 'This fire is WAY too close wtf is going on ???? http://t.co/drf3mmRbyx',\n",
       " 'New Giant Flames (GIANT FULL BLACK PANTOFEL) info/order sms:087809233445 pin:23928835 http://t.co/dthNEezupe  pic.twitter.com/pNPiZoDY',\n",
       " 'Zimbabwe is a country with a collapsed government ruled by a dictator while many live below the poverty line.',\n",
       " 'Look at the previous battles. Citizens were committing suicide so to not be under American control. The bomb was the only way. @NBCNews',\n",
       " '3 Options To Fix Your Facebook Cover Violation http://t.co/pF8dXwIbDp and Keep the #Facebook Police away. #socialmedia #strategy',\n",
       " 'Passengers evacuated &amp; lanes blocked off as power lines come down over a Gold Coast tram @9NewsGoldCoast http://t.co/zZweEezJuG',\n",
       " \"Waking up sick with a rainstorm outside would usually make me sad. Not today though. Put some The Kooks on the stereo and let's do this.\"]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.choices(train_text, k =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4a7b407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.03743596479706"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt_list = []\n",
    "leng = 0\n",
    "for text in train_text:\n",
    "    plt_list.append(len(text))\n",
    "    leng =leng + len(text)\n",
    "\n",
    "leng/len(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7d9bf9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(plt_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b822633b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pittsburgh ',\n",
       " 'none',\n",
       " 'Miami Beach, Fl',\n",
       " 'none',\n",
       " 'Charlotte NC',\n",
       " 'Bend, Oregon',\n",
       " 'Anderson, SC',\n",
       " 'Los Angeles, CA',\n",
       " 'United Kingdom',\n",
       " 'none']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(train_location , k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7b32123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attack',\n",
       " 'structural%20failure',\n",
       " 'whirlwind',\n",
       " 'heat%20wave',\n",
       " 'twister',\n",
       " 'airplane%20accident',\n",
       " 'devastation',\n",
       " 'typhoon',\n",
       " 'harm',\n",
       " 'disaster']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(train_keyword, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a3e80071",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 10000\n",
    "output_length = 150\n",
    "\n",
    "text_vector = layers.TextVectorization(max_tokens = max_vocab , output_sequence_length=output_length )\n",
    "\n",
    "text_embed = layers.Embedding(max_vocab, 128, mask_zero=True)\n",
    "\n",
    "text_vector.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25a0af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences , train_target , val_target = train_test_split(\n",
    "                                                                train_text,\n",
    "                                                                train_label,\n",
    "                                                                test_size = 0.3,\n",
    "                                                                random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc51cd",
   "metadata": {},
   "source": [
    "## Creating a dataset for the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "559e3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_0 = tf.data.Dataset.from_tensor_slices((train_sentences, train_target))\n",
    "val_dataset_0 = tf.data.Dataset.from_tensor_slices((val_sentences, val_target))\n",
    "\n",
    "\n",
    "train_dataset_0 = train_dataset_0.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset_0 = val_dataset_0.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d682a534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "acbb07d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None,), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_0.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741b9de",
   "metadata": {},
   "source": [
    "## Creating our first model using simple CNN method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e930ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 150)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 150, 128)          1280000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 149, 64)           16448     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,304,833\n",
      "Trainable params: 1,304,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape = (1,) , dtype = tf.string)\n",
    "\n",
    "x = text_vector(inputs)\n",
    "x = text_embed(x)\n",
    "\n",
    "x = layers.Conv1D(64, 2, activation = \"tanh\")(x)\n",
    "\n",
    "\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dense(64 , activation = \"tanh\")(x)\n",
    "x = layers.Dense(64, activation = \"tanh\")(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "model_0 = tf.keras.Model(inputs , outputs)\n",
    "\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27850158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 10s 46ms/step - loss: 0.6832 - accuracy: 0.5772 - val_loss: 0.6540 - val_accuracy: 0.5775\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.4892 - accuracy: 0.7652 - val_loss: 0.5041 - val_accuracy: 0.7859\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 7s 44ms/step - loss: 0.3497 - accuracy: 0.8473 - val_loss: 0.4907 - val_accuracy: 0.8117\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 0.2762 - accuracy: 0.8891 - val_loss: 0.5288 - val_accuracy: 0.8122\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.2342 - accuracy: 0.9097 - val_loss: 0.6094 - val_accuracy: 0.7964\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 0.2282 - accuracy: 0.9097 - val_loss: 0.6778 - val_accuracy: 0.7863\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 8s 51ms/step - loss: 0.2177 - accuracy: 0.9077 - val_loss: 0.6055 - val_accuracy: 0.7872\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 0.1619 - accuracy: 0.9362 - val_loss: 0.8626 - val_accuracy: 0.7032\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.1316 - accuracy: 0.9503 - val_loss: 1.0816 - val_accuracy: 0.6524\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 0.1188 - accuracy: 0.9578 - val_loss: 0.9496 - val_accuracy: 0.7001\n"
     ]
    }
   ],
   "source": [
    "model_0.compile(loss = \"binary_crossentropy\",\n",
    "               optimizer = \"adam\",\n",
    "               metrics = [\"accuracy\"])\n",
    "\n",
    "model_0_history = model_0.fit(train_dataset_0, \n",
    "           epochs = 10 ,\n",
    "           validation_data=val_dataset_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3386f893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186    0\n",
       "4071    1\n",
       "5461    1\n",
       "5787    1\n",
       "7445    0\n",
       "       ..\n",
       "5226    0\n",
       "5390    0\n",
       "860     0\n",
       "7603    1\n",
       "7270    1\n",
       "Name: target, Length: 5329, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f67bc",
   "metadata": {},
   "source": [
    "## Visualizing the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d7c96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 1s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 70.00875656742556,\n",
       " 'precision': 0.7397661357946943,\n",
       " 'recall': 0.7000875656742557,\n",
       " 'f1': 0.7005834785893477}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_preds = model_0.predict(val_dataset_0)\n",
    "model_0_results = calculate_results(tf.round(model_0_preds), val_target)\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c77ef5",
   "metadata": {},
   "source": [
    "## Creating a character level dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6fb14e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s o   y o u   h a v e   a   n e w   w e a p o n   t h a t   c a n   c a u s e   u n - i m a g i n a b l e   d e s t r u c t i o n .',\n",
       " 't h e   f $ & a m p ; @ i n g   t h i n g s   i   d o   f o r   # g i s h w h e s   j u s t   g o t   s o a k e d   i n   a   d e l u g e   g o i n g   f o r   p a d s   a n d   t a m p o n s .   t h x   @ m i s h a c o l l i n s   @ / @',\n",
       " 'd t   @ g e o r g e g a l l o w a y :   r t   @ g a l l o w a y 4 m a y o r :   \\x89 û ï t h e   c o l   p o l i c e   c a n   c a t c h   a   p i c k p o c k e t   i n   l i v e r p o o l   s t r e e . . .   h t t p : / / t . c o / v x i n 1 g o q 4 q',\n",
       " 'a f t e r s h o c k   b a c k   t o   s c h o o l   k i c k   o f f   w a s   g r e a t .   i   w a n t   t o   t h a n k   e v e r y o n e   f o r   m a k i n g   i t   p o s s i b l e .   w h a t   a   g r e a t   n i g h t .',\n",
       " 'i n   r e s p o n s e   t o   t r a u m a   c h i l d r e n   o f   a d d i c t s   d e v e l o p   a   d e f e n s i v e   s e l f   -   o n e   t h a t   d e c r e a s e s   v u l n e r a b i l i t y .   ( 3',\n",
       " '@ c a l u m 5 s o s   y o u   l o o k   l i k e   y o u   g o t   c a u g h t   i n   a   r a i n s t o r m   t h i s   i s   a m a z i n g   a n d   d i s g u s t i n g   a t   t h e   s a m e   t i m e',\n",
       " 'm y   f a v o r i t e   l a d y   c a m e   t o   o u r   v o l u n t e e r   m e e t i n g \\n h o p e f u l l y   j o i n i n g   h e r   y o u t h   c o l l i s i o n   a n d   i   a m   e x c i t e   h t t p : / / t . c o / i j 0 w q 4 9 0 c s',\n",
       " '@ b r i a n r o e m m e l e   u x   f a i l   o f   e m v   -   p e o p l e   w a n t   t o   i n s e r t   a n d   r e m o v e   q u i c k l y   l i k e   a   g a s   p u m p   s t r i p e   r e a d e r .   1   p e r s o n   t o l d   m e   i t   c r a s h e d   t h e   p o s',\n",
       " \"c a n ' t   f i n d   m y   a r i a n a   g r a n d e   s h i r t     t h i s   i s   a   f u c k i n g   t r a g e d y\",\n",
       " 't h e   m u r d e r o u s   s t o r y   o f   a m e r i c a \\x89 û ª s   f i r s t   h i j a c k i n g   h t t p : / / t . c o / e y u g k 6 b y x r']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_char_text = [\" \".join(list(text.lower())) for text in train_sentences]\n",
    "val_char_text = [\" \".join(list(text.lower())) for text in val_sentences]\n",
    "test_char_text = [\" \".join(list(text.lower())) for text in test_text]\n",
    "\n",
    "\n",
    "val_char_text[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f1a8379b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_1 = tf.data.Dataset.from_tensor_slices((train_char_text, train_target)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset_1 = tf.data.Dataset.from_tensor_slices((val_char_text, val_target)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "429d0ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 449., 1255., 2072., 2488., 2818.,  643.,  747.,  710., 1658.,\n",
       "         102.]),\n",
       " array([  7. ,  37.6,  68.2,  98.8, 129.4, 160. , 190.6, 221.2, 251.8,\n",
       "        282.4, 313. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for text in train_char_text:\n",
    "    plt_list.append(len(text))\n",
    "\n",
    "plt.hist(plt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd930809",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_length = 68\n",
    "\n",
    "char_vector = layers.TextVectorization(max_tokens = char_length+2 , output_sequence_length=280 )\n",
    "\n",
    "char_embed = layers.Embedding(char_length+2 , 128, mask_zero= True)\n",
    "\n",
    "char_vector.adapt(train_char_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa58eaf",
   "metadata": {},
   "source": [
    "## Creating a convulation model using character token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e0a08eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 280)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 280, 128)          8960      \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 280, 100)          12900     \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 138, 264)          132264    \n",
      "                                                                 \n",
      " global_max_pooling1d_8 (Glo  (None, 264)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 100)               26500     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,725\n",
      "Trainable params: 180,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
    "x = char_vector(inputs)\n",
    "x = char_embed(x)\n",
    "\n",
    "\n",
    "x = layers.Dense(100,activation = \"tanh\")(x)\n",
    "x = layers.Conv1D(264, 5, 2, activation = \"tanh\")(x)\n",
    "\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "\n",
    "\n",
    "\n",
    "x = layers.Dense(100,activation = \"tanh\")(x)\n",
    "outputs = layers.Dense(1 , activation = \"sigmoid\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0514e010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 29s 166ms/step - loss: 0.6515 - accuracy: 0.6208 - val_loss: 0.5933 - val_accuracy: 0.6922\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 25s 153ms/step - loss: 0.5450 - accuracy: 0.7251 - val_loss: 0.5333 - val_accuracy: 0.7347\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 27s 161ms/step - loss: 0.4525 - accuracy: 0.7895 - val_loss: 0.5413 - val_accuracy: 0.7268\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 28s 169ms/step - loss: 0.3630 - accuracy: 0.8442 - val_loss: 0.6314 - val_accuracy: 0.6909\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 30s 183ms/step - loss: 0.2652 - accuracy: 0.8996 - val_loss: 0.7356 - val_accuracy: 0.6764\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 27s 163ms/step - loss: 0.2241 - accuracy: 0.9114 - val_loss: 1.1285 - val_accuracy: 0.6878\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 31s 183ms/step - loss: 0.3069 - accuracy: 0.8609 - val_loss: 0.8497 - val_accuracy: 0.7202\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 27s 163ms/step - loss: 0.3073 - accuracy: 0.8625 - val_loss: 0.7593 - val_accuracy: 0.7250\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 27s 160ms/step - loss: 0.2465 - accuracy: 0.8934 - val_loss: 0.7333 - val_accuracy: 0.6874\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 27s 161ms/step - loss: 0.2042 - accuracy: 0.9195 - val_loss: 1.4930 - val_accuracy: 0.5381\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(loss = \"binary_crossentropy\",\n",
    "               optimizer = \"adam\",\n",
    "               metrics = [\"accuracy\"])\n",
    "\n",
    "model_1_history = model_1.fit(train_dataset_1, epochs = 10 , validation_data=val_dataset_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641f9ae",
   "metadata": {},
   "source": [
    "## Visualizing the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "469b78e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 4s 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 49.69352014010508,\n",
       " 'precision': 0.9092435055272563,\n",
       " 'recall': 0.4969352014010508,\n",
       " 'f1': 0.5897513063428701}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds = model_1.predict(val_char_text)\n",
    "model_1_preds = tf.round(model_1_preds)\n",
    "\n",
    "model_1_results = calculate_resultsulate_resultsulate_resultsulate_results(model_1_preds, val_target)\n",
    "\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c76a3",
   "metadata": {},
   "source": [
    "## Creating a Recurrent Neural Network using Character token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ddb1a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 280)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 280, 128)          8960      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 280, 100)          12900     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 280, 500)          50500     \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 528)              1615680   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 100)               52900     \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,741,041\n",
      "Trainable params: 1,741,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape = (1, ) , dtype = tf.string)\n",
    "x = char_vector(inputs)\n",
    "x = char_embed(x)\n",
    "\n",
    "x = layers.Dense(100, activation = \"tanh\")(x)\n",
    "x = layers.Dense(500, activation = \"tanh\")(x)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(264))(x)\n",
    "\n",
    "\n",
    "\n",
    "x = layers.Dense(100, activation = \"tanh\")(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4078cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 9819s 59s/step - loss: 0.6516 - accuracy: 0.6239 - val_loss: 0.6497 - val_accuracy: 0.6156\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 1438s 9s/step - loss: 0.6462 - accuracy: 0.6322 - val_loss: 0.6333 - val_accuracy: 0.6401\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 1683s 10s/step - loss: 0.6351 - accuracy: 0.6500 - val_loss: 0.6596 - val_accuracy: 0.6116\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2028s 12s/step - loss: 0.6392 - accuracy: 0.6356 - val_loss: 0.6328 - val_accuracy: 0.6410\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 5762s 35s/step - loss: 0.6405 - accuracy: 0.6315 - val_loss: 0.6348 - val_accuracy: 0.6445\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 1722s 10s/step - loss: 0.6238 - accuracy: 0.6583 - val_loss: 0.6303 - val_accuracy: 0.6462\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 3172s 19s/step - loss: 0.6244 - accuracy: 0.6551 - val_loss: 0.6317 - val_accuracy: 0.6506\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 1811s 11s/step - loss: 0.5984 - accuracy: 0.6831 - val_loss: 0.6100 - val_accuracy: 0.6673\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2810s 17s/step - loss: 0.5672 - accuracy: 0.7099 - val_loss: 0.6065 - val_accuracy: 0.6756\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 3442s 21s/step - loss: 0.5311 - accuracy: 0.7394 - val_loss: 0.6033 - val_accuracy: 0.6852\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(loss = \"binary_crossentropy\",\n",
    "               optimizer = \"adam\",\n",
    "               metrics = [\"accuracy\"])\n",
    "\n",
    "model_2_history = model_2.fit(train_dataset_1, epochs = 10 , validation_data=val_dataset_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe64bdf3",
   "metadata": {},
   "source": [
    "## visualizing our model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02c554b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 256s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 65.19264448336253,\n",
       " 'precision': 0.6991837510613002,\n",
       " 'recall': 0.6519264448336253,\n",
       " 'f1': 0.6654859452107369}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds =  model_2.predict(val_char_text)\n",
    "model_2_preds = tf.round(model_2_preds)\n",
    "\n",
    "model_2_results = calculate_results(model_2_preds, val_target)\n",
    "\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87f5ce",
   "metadata": {},
   "source": [
    "## Creating a Recurrent Neural Network model using text token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59adcd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 280)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 280, 128)          8960      \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 280, 100)          12900     \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 280, 500)          50500     \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 256)              644096    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 100)               25700     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 742,257\n",
      "Trainable params: 742,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape = (1, ) , dtype = tf.string)\n",
    "x = char_vector(inputs)\n",
    "x = char_embed(x)\n",
    "\n",
    "x = layers.Dense(100, activation = \"relu\")(x)\n",
    "x = layers.Dense(500, activation = \"relu\")(x)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(128))(x)\n",
    "\n",
    "\n",
    "\n",
    "x = layers.Dense(100, activation = \"relu\")(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4df50f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "167/167 [==============================] - 392s 2s/step - loss: 0.6725 - accuracy: 0.5652 - val_loss: 0.6620 - val_accuracy: 0.5784\n",
      "Epoch 2/5\n",
      "167/167 [==============================] - 493s 3s/step - loss: 0.6642 - accuracy: 0.5676 - val_loss: 0.6659 - val_accuracy: 0.5705\n",
      "Epoch 3/5\n",
      "167/167 [==============================] - 481s 3s/step - loss: 0.6635 - accuracy: 0.5705 - val_loss: 0.6634 - val_accuracy: 0.5775\n",
      "Epoch 4/5\n",
      "167/167 [==============================] - 673s 4s/step - loss: 0.6604 - accuracy: 0.5744 - val_loss: 0.6635 - val_accuracy: 0.5863\n",
      "Epoch 5/5\n",
      "167/167 [==============================] - 466s 3s/step - loss: 0.6578 - accuracy: 0.5770 - val_loss: 0.6609 - val_accuracy: 0.5744\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(loss = \"binary_crossentropy\",\n",
    "               optimizer = \"adam\",\n",
    "               metrics = [\"accuracy\"])\n",
    "\n",
    "model_3_history = model_3.fit(train_dataset_0, epochs = 5 , validation_data=val_dataset_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5fcb6d",
   "metadata": {},
   "source": [
    "## Visualizing our model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd39b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 59s 764ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 57.4430823117338,\n",
       " 'precision': 0.5977839667274372,\n",
       " 'recall': 0.574430823117338,\n",
       " 'f1': 0.5738385051830046}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds =  model_3.predict(val_dataset_0)\n",
    "model_3_preds = tf.round(model_3_preds)\n",
    "\n",
    "model_3_results = calculate_results(model_3_preds, val_target)\n",
    "\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29e98e6",
   "metadata": {},
   "source": [
    "## Creating concatenate model (char text model + location model + keyboard model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50e57f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99775e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7613 entries, 4042 to 5722\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7613 non-null   object\n",
      " 2   location  7613 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 356.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ef711d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent = train_data[\"text\"][:6500]\n",
    "train_keyword = train_data[\"keyword\"][:6500]\n",
    "train_location = train_data[\"location\"][:6500]\n",
    "train_target = train_data[\"target\"][:6500]\n",
    "\n",
    "val_sent = train_data[\"text\"][6500:]\n",
    "val_keyword = train_data[\"keyword\"][6500:]\n",
    "val_location = train_data[\"location\"][6500:]\n",
    "val_target = train_data[\"target\"][6500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2d913be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent_text = [\" \".join(list(text.lower())) for text in train_sent]\n",
    "val_sent_text = [\" \".join(list(text.lower())) for text in val_sent]\n",
    "test_char_text = [\" \".join(list(text.lower())) for text in test_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e63436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_length = 68\n",
    "\n",
    "char_vector = layers.TextVectorization(max_tokens = char_length+2 , output_sequence_length=280 )\n",
    "\n",
    "char_embed = layers.Embedding(char_length+2 , 128, mask_zero= True)\n",
    "\n",
    "char_vector.adapt(train_sent_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca09268",
   "metadata": {},
   "source": [
    "## Creating a dataset for our final model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "afc414aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(c_data, keyword, location, target):\n",
    "    x = tf.data.Dataset.from_tensor_slices((c_data ,keyword,location))\n",
    "    y = tf.data.Dataset.from_tensor_slices(target)\n",
    "    z = tf.data.Dataset.zip((x,y)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3309940",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_train_dataset = transforms(train_sent_text,\n",
    "                                      train_keyword, \n",
    "                                      train_location,\n",
    "                                      train_target)\n",
    "\n",
    "positional_val_dataset = transforms(val_sent_text,\n",
    "                                    val_keyword,\n",
    "                                    val_location,\n",
    "                                    val_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "57719033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=((TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None)), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd91ec",
   "metadata": {},
   "source": [
    "### Creating model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "11268175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"final_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization_5 (TextVect  (None, 280)         0           ['input_1[0][0]',                \n",
      " orization)                                                       'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 280, 128)     8960        ['text_vectorization_5[0][0]',   \n",
      "                                                                  'text_vectorization_5[1][0]',   \n",
      "                                                                  'text_vectorization_5[2][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 280, 100)     12900       ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 280, 100)     12900       ['embedding_5[1][0]']            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 280, 100)     12900       ['embedding_5[2][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 280, 500)     50500       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 280, 500)     50500       ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 280, 500)     50500       ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 256)          644096      ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 256)         644096      ['dense_4[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 256)         644096      ['dense_7[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            257         ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            257         ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1)            257         ['bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3)            0           ['dense_2[0][0]',                \n",
      "                                                                  'dense_5[0][0]',                \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            4           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,132,223\n",
      "Trainable params: 2,132,223\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# char text model\n",
    "\n",
    "inputs = layers.Input(shape = (1, ) , dtype = tf.string)\n",
    "char_vectorizer = char_vector(inputs)\n",
    "char_embedding = char_embed(char_vectorizer)\n",
    "\n",
    "x = layers.Dense(100, activation = \"relu\")(char_embedding)\n",
    "x = layers.Dense(500, activation = \"relu\")(x)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(128))(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "char_model = tf.keras.Model(inputs, outputs , name = \"character_model\")\n",
    "\n",
    "# keyword model\n",
    "\n",
    "inputs = layers.Input(shape = (1, ) , dtype = tf.string)\n",
    "char_vectorizer = char_vector(inputs)\n",
    "char_embedding = char_embed(char_vectorizer)\n",
    "\n",
    "x = layers.Dense(100, activation = \"relu\")(char_embedding)\n",
    "x = layers.Dense(500, activation = \"relu\")(x)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(128))(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "keyword_model = tf.keras.Model(inputs, outputs , name = \"keyword_model\")\n",
    "\n",
    "# location model \n",
    "\n",
    "inputs = layers.Input(shape = (1, ) , dtype = tf.string)\n",
    "char_vectorizer = char_vector(inputs)\n",
    "char_embedding = char_embed(char_vectorizer)\n",
    "\n",
    "x = layers.Dense(100, activation = \"relu\")(char_embedding)\n",
    "x = layers.Dense(500, activation = \"relu\")(x)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(128))(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "location_model = tf.keras.Model(inputs, outputs , name = \"location_model\")\n",
    "\n",
    "# concatenation of all the model\n",
    "\n",
    "char_concat = layers.Concatenate()([ char_model.output, keyword_model.output, location_model.output])\n",
    "\n",
    "# using some dropout\n",
    "\n",
    "dropout_layers = layers.Dropout(0.5)(char_concat)\n",
    "\n",
    "\n",
    "\n",
    "# final output layers\n",
    "\n",
    "output_layer = layers.Dense(1 , activation = \"sigmoid\")(char_concat)\n",
    "\n",
    "# final model \n",
    "\n",
    "model_5 = tf.keras.Model( [char_model.input, keyword_model.input,location_model.input], output_layer , name = \"final_model\")\n",
    "\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c69dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "204/204 [==============================] - 1257s 6s/step - loss: 0.6825 - accuracy: 0.5728 - val_loss: 0.6842 - val_accuracy: 0.5624\n",
      "Epoch 2/10\n",
      "204/204 [==============================] - 38565s 190s/step - loss: 0.6740 - accuracy: 0.5868 - val_loss: 0.6636 - val_accuracy: 0.5975\n",
      "Epoch 3/10\n",
      "204/204 [==============================] - 1161s 6s/step - loss: 0.6562 - accuracy: 0.6266 - val_loss: 0.6530 - val_accuracy: 0.6415\n",
      "Epoch 4/10\n",
      "204/204 [==============================] - 1198s 6s/step - loss: 0.6501 - accuracy: 0.6400 - val_loss: 0.6459 - val_accuracy: 0.6460\n",
      "Epoch 5/10\n",
      "204/204 [==============================] - ETA: 0s - loss: 0.6400 - accuracy: 0.6586Epoch 6/10\n",
      "198/204 [============================>.] - ETA: 1:26 - loss: 0.6303 - accuracy: 0.6776"
     ]
    }
   ],
   "source": [
    "model_5.compile(loss = \"binary_crossentropy\",\n",
    "               optimizer = \"adam\",\n",
    "               metrics = [\"accuracy\"])\n",
    "\n",
    "model_5_history = model_5.fit(positional_train_dataset, epochs = 10 , validation_data=positional_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20238585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
